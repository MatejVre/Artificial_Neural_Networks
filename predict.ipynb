{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "02cd8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from nn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab8769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"image1-competition.hdf5\"\n",
    "\n",
    "with h5py.File(fn, \"r\") as f:\n",
    "    data = np.array(f[\"data\"])\n",
    "    wns = np.array(f[\"wns\"])\n",
    "    tissue_mask = np.array(f[\"tissue_mask\"])\n",
    "    classes = np.array(f[\"classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58162248",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predict = data[265:465,360:660]\n",
    "average_spectrum = np.mean(data_predict, axis=(0, 1))\n",
    "# plt.plot(wns, average_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6025f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(a, b):\n",
    "    return 1 - np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5aa135c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.00020927191)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = data[475:580, 870:1000, :]\n",
    "average_spectrum2 = np.mean(X_test, axis=(0, 1))\n",
    "cosine_distance(average_spectrum2, average_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "7f24270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matej\\AppData\\Local\\Temp\\ipykernel_30748\\2332967178.py:5: RuntimeWarning: invalid value encountered in cast\n",
      "  data_with_coords = np.concatenate([data, coords], axis=-1)\n"
     ]
    }
   ],
   "source": [
    "h, w = data.shape[:2]\n",
    "xx, yy = np.meshgrid(np.arange(w), np.arange(h))\n",
    "coords = np.stack((yy, xx), axis=-1)\n",
    "\n",
    "data_with_coords = np.concatenate([data, coords], axis=-1)\n",
    "\n",
    "X_test = data_with_coords[475:580, 870:1000, :]\n",
    "y_test = classes[475:580, 870:1000]\n",
    "\n",
    "train_data = np.delete(data_with_coords, slice(475, 580), axis=0)\n",
    "X_train = np.delete(train_data, slice(870, 1000), axis=1)\n",
    "\n",
    "train_data_y = np.delete(classes, slice(475, 580), axis=0)\n",
    "y_train = np.delete(train_data_y, slice(870, 1000), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "96fc30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_sel_test = y_test != -1\n",
    "\n",
    "X_test = X_test[annotated_sel_test, :]\n",
    "y_test = y_test[annotated_sel_test]\n",
    "\n",
    "\n",
    "annotated_sel_train = y_train != -1\n",
    "X_train = X_train[annotated_sel_train]\n",
    "y_train = y_train[annotated_sel_train]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2255528f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31548, 189)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "c538712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(189, 20),\n",
    "            nn.Tanh(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.Tanh(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(20, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)  # or nn.init.kaiming_uniform_\n",
    "                nn.init.zeros_(m.bias)\n",
    "    \n",
    "def train(X, y, model, learning_rate, num_epochs, loss_fn, X_test, y_test, validation=False):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.005)\n",
    "    model.train()\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Forward pass\n",
    "        preds = model(X)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(preds, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Print loss after each epoch\n",
    "        if (epoch + 1) % 5 == 0:  # Print every 10 epochs (adjust as needed)\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Zero gradients for the next step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if validation:      \n",
    "            # Validation step\n",
    "            model.eval()  # Switch to evaluation mode (disables dropout, batch norm, etc.)\n",
    "            with torch.no_grad():  # Disable gradient calculation for validation to save memory and computation\n",
    "                val_preds = model(X_test)\n",
    "                val_loss = loss_fn(val_preds, y_test)\n",
    "            \n",
    "            # Print validation loss after each epoch\n",
    "            if (epoch + 1) % 5 == 0:  # Print every 10 epochs (adjust as needed)\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss.item():.4f}\")\n",
    "            \n",
    "        model.train() \n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "def test(X_test, y_test, model, loss_fn):\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout, batch norm, etc.)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():  # No gradient tracking needed for inference\n",
    "        preds = model(X_test)\n",
    "    # Convert predictions to class labels (for classification)\n",
    "    _, predicted = torch.max(preds, 1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = (predicted == y_test).sum().item()\n",
    "    total = y_test.size(0)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    # Calculate cross-entropy loss\n",
    "    print(y_test.shape)\n",
    "    loss = loss_fn(preds, y_test)\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Test Loss (Cross-Entropy): {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ed73a",
   "metadata": {},
   "source": [
    "0.005, 110, 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "5800612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/110], Loss: 1.4176\n",
      "Epoch [5/110], Validation Loss: 1.5386\n",
      "Epoch [10/110], Loss: 1.2171\n",
      "Epoch [10/110], Validation Loss: 1.3593\n",
      "Epoch [15/110], Loss: 1.0575\n",
      "Epoch [15/110], Validation Loss: 1.3581\n",
      "Epoch [20/110], Loss: 0.9183\n",
      "Epoch [20/110], Validation Loss: 1.4990\n",
      "Epoch [25/110], Loss: 0.7905\n",
      "Epoch [25/110], Validation Loss: 1.6492\n",
      "Epoch [30/110], Loss: 0.6795\n",
      "Epoch [30/110], Validation Loss: 1.6847\n",
      "Epoch [35/110], Loss: 0.5886\n",
      "Epoch [35/110], Validation Loss: 1.5105\n",
      "Epoch [40/110], Loss: 0.5190\n",
      "Epoch [40/110], Validation Loss: 1.0697\n",
      "Epoch [45/110], Loss: 0.4710\n",
      "Epoch [45/110], Validation Loss: 0.8767\n",
      "Epoch [50/110], Loss: 0.4336\n",
      "Epoch [50/110], Validation Loss: 0.7834\n",
      "Epoch [55/110], Loss: 0.4038\n",
      "Epoch [55/110], Validation Loss: 0.5769\n",
      "Epoch [60/110], Loss: 0.3793\n",
      "Epoch [60/110], Validation Loss: 0.5092\n",
      "Epoch [65/110], Loss: 0.3593\n",
      "Epoch [65/110], Validation Loss: 0.4736\n",
      "Epoch [70/110], Loss: 0.3427\n",
      "Epoch [70/110], Validation Loss: 0.4411\n",
      "Epoch [75/110], Loss: 0.3286\n",
      "Epoch [75/110], Validation Loss: 0.4528\n",
      "Epoch [80/110], Loss: 0.3169\n",
      "Epoch [80/110], Validation Loss: 0.4311\n",
      "Epoch [85/110], Loss: 0.3069\n",
      "Epoch [85/110], Validation Loss: 0.4483\n",
      "Epoch [90/110], Loss: 0.2979\n",
      "Epoch [90/110], Validation Loss: 0.4352\n",
      "Epoch [95/110], Loss: 0.2898\n",
      "Epoch [95/110], Validation Loss: 0.4269\n",
      "Epoch [100/110], Loss: 0.2824\n",
      "Epoch [100/110], Validation Loss: 0.4155\n",
      "Epoch [105/110], Loss: 0.2757\n",
      "Epoch [105/110], Validation Loss: 0.4276\n",
      "Epoch [110/110], Loss: 0.2729\n",
      "Epoch [110/110], Validation Loss: 0.3321\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "train(X_train_tensor, y_train_tensor, model, 0.005, 110, nn.CrossEntropyLoss(), X_test_tensor, y_test_tensor, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "9d50a0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200])\n",
      "Test Accuracy: 91.92%\n",
      "Test Loss (Cross-Entropy): 0.3321\n"
     ]
    }
   ],
   "source": [
    "test(X_test_tensor, y_test_tensor, model, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "98baceb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/110], Loss: 1.3211\n",
      "Epoch [10/110], Loss: 1.0689\n",
      "Epoch [15/110], Loss: 0.8637\n",
      "Epoch [20/110], Loss: 0.6744\n",
      "Epoch [25/110], Loss: 0.5452\n",
      "Epoch [30/110], Loss: 0.4794\n",
      "Epoch [35/110], Loss: 0.4276\n",
      "Epoch [40/110], Loss: 0.3872\n",
      "Epoch [45/110], Loss: 0.3595\n",
      "Epoch [50/110], Loss: 0.3375\n",
      "Epoch [55/110], Loss: 0.3176\n",
      "Epoch [60/110], Loss: 0.3070\n",
      "Epoch [65/110], Loss: 0.2902\n",
      "Epoch [70/110], Loss: 0.2797\n",
      "Epoch [75/110], Loss: 0.2698\n",
      "Epoch [80/110], Loss: 0.2636\n",
      "Epoch [85/110], Loss: 0.2559\n",
      "Epoch [90/110], Loss: 0.2664\n",
      "Epoch [95/110], Loss: 0.2446\n",
      "Epoch [100/110], Loss: 0.2410\n",
      "Epoch [105/110], Loss: 0.2375\n",
      "Epoch [110/110], Loss: 0.2336\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "annotated_sel = classes != -1\n",
    "X_real = data_with_coords[annotated_sel]\n",
    "y_real = classes[annotated_sel]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_real = scaler.fit_transform(X_real)\n",
    "\n",
    "data_predict = data_with_coords[265:465,360:660]\n",
    "\n",
    "X_real = torch.tensor(X_real, dtype=torch.float32)\n",
    "y_real = torch.tensor(y_real, dtype=torch.long)\n",
    "train(X_real, y_real, model, 0.01, 110, nn.CrossEntropyLoss(), [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "fc0ee47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 300, 6)\n"
     ]
    }
   ],
   "source": [
    "lin_data_predict = data_predict.reshape(-1, data_predict.shape[-1])\n",
    "lin_data_predict = scaler.transform(lin_data_predict)\n",
    "\n",
    "lin_data_predict = torch.tensor(lin_data_predict, dtype=torch.float32)\n",
    "pred = model(lin_data_predict)\n",
    "pred = torch.softmax(pred, dim=1)\n",
    "pred = pred.reshape((200, 300, -1)).detach().numpy()\n",
    "print(pred.shape)\n",
    "\n",
    "with open(\"first.npy\", \"wb\") as f:\n",
    "    np.save(f, pred.astype(np.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDS_HW1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
