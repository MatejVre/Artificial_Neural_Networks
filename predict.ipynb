{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02cd8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab8769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"image1-competition.hdf5\"\n",
    "\n",
    "with h5py.File(fn, \"r\") as f:\n",
    "    data = np.array(f[\"data\"])\n",
    "    wns = np.array(f[\"wns\"])\n",
    "    tissue_mask = np.array(f[\"tissue_mask\"])\n",
    "    classes = np.array(f[\"classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f24270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data[475:700, 750:1000, :]\n",
    "y_test = classes[475:700, 750:1000]\n",
    "\n",
    "train_data = np.delete(data, slice(475, 700), axis=0)\n",
    "X_train = np.delete(train_data, slice(750, 1000), axis=1)\n",
    "\n",
    "train_data_y = np.delete(classes, slice(475, 700), axis=0)\n",
    "y_train = np.delete(train_data_y, slice(750, 1000), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96fc30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_sel_test = y_test != -1\n",
    "\n",
    "X_test = X_test[annotated_sel_test, :]\n",
    "y_test = y_test[annotated_sel_test]\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "annotated_sel_train = y_train != -1\n",
    "X_train = X_train[annotated_sel_train]\n",
    "y_train = y_train[annotated_sel_train]\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2255528f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([139212150])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c538712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(187, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "def train(X, y, model, learning_rate, num_epochs, loss_fn):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Forward pass\n",
    "        preds = model(X)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(preds, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Print loss after each epoch\n",
    "        if (epoch + 1) % 10 == 0:  # Print every 10 epochs (adjust as needed)\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Zero gradients for the next step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "def test(X_test, y_test, model, loss_fn):\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout, batch norm, etc.)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():  # No gradient tracking needed for inference\n",
    "        preds = model(X_test)\n",
    "    print(preds.shape)\n",
    "    # Convert predictions to class labels (for classification)\n",
    "    _, predicted = torch.max(preds, 1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = (predicted == y_test).sum().item()\n",
    "    total = y_test.size(0)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    # Calculate cross-entropy loss\n",
    "    print(y_test.shape)\n",
    "    loss = loss_fn(preds, y_test)\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Test Loss (Cross-Entropy): {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5800612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 1.4804\n",
      "Epoch [20/200], Loss: 1.4437\n",
      "Epoch [30/200], Loss: 1.3615\n",
      "Epoch [40/200], Loss: 1.0562\n",
      "Epoch [50/200], Loss: 0.8307\n",
      "Epoch [60/200], Loss: 0.7129\n",
      "Epoch [70/200], Loss: 0.6738\n",
      "Epoch [80/200], Loss: 0.6417\n",
      "Epoch [90/200], Loss: 0.6110\n",
      "Epoch [100/200], Loss: 0.5841\n",
      "Epoch [110/200], Loss: 0.5709\n",
      "Epoch [120/200], Loss: 0.5616\n",
      "Epoch [130/200], Loss: 0.5538\n",
      "Epoch [140/200], Loss: 0.5408\n",
      "Epoch [150/200], Loss: 0.5287\n",
      "Epoch [160/200], Loss: 0.5210\n",
      "Epoch [170/200], Loss: 0.5080\n",
      "Epoch [180/200], Loss: 0.5020\n",
      "Epoch [190/200], Loss: 0.4853\n",
      "Epoch [200/200], Loss: 0.4871\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "train(X_train, y_train, model, 0.01, 200, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50a0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5192, 6])\n",
      "torch.Size([5192])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mtest\u001b[39m\u001b[34m(X_test, y_test, model, loss_fn)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Calculate cross-entropy loss\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(y_test.shape)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m loss = \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest Loss (Cross-Entropy): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matej\\miniconda3\\envs\\MLDS_HW1\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1292\u001b[39m, in \u001b[36mCrossEntropyLoss.__init__\u001b[39m\u001b[34m(self, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   1283\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1285\u001b[39m     weight: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1290\u001b[39m     label_smoothing: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.0\u001b[39m,\n\u001b[32m   1291\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1292\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1293\u001b[39m     \u001b[38;5;28mself\u001b[39m.ignore_index = ignore_index\n\u001b[32m   1294\u001b[39m     \u001b[38;5;28mself\u001b[39m.label_smoothing = label_smoothing\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matej\\miniconda3\\envs\\MLDS_HW1\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:57\u001b[39m, in \u001b[36m_WeightedLoss.__init__\u001b[39m\u001b[34m(self, weight, size_average, reduce, reduction)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     51\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     52\u001b[39m     weight: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m     reduction: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     56\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mself\u001b[39m.register_buffer(\u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m, weight)\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mself\u001b[39m.weight: Optional[Tensor]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matej\\miniconda3\\envs\\MLDS_HW1\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:44\u001b[39m, in \u001b[36m_Loss.__init__\u001b[39m\u001b[34m(self, size_average, reduce, reduction)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28mself\u001b[39m.reduction: \u001b[38;5;28mstr\u001b[39m = \u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlegacy_get_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mself\u001b[39m.reduction = reduction\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matej\\miniconda3\\envs\\MLDS_HW1\\Lib\\site-packages\\torch\\nn\\_reduction.py:44\u001b[39m, in \u001b[36mlegacy_get_string\u001b[39m\u001b[34m(size_average, reduce, emit_warning)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     42\u001b[39m     reduce = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mand\u001b[39;00m reduce:\n\u001b[32m     45\u001b[39m     ret = \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m reduce:\n",
      "\u001b[31mRuntimeError\u001b[39m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "test(X_test, y_test, model, nn.CrossEntropyLoss())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDS_HW1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
